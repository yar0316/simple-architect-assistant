"""Streamlit UIé–¢é€£ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
import streamlit as st
import json
from typing import Dict, Any, Optional

def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "ã©ã®ã‚ˆã†ãªAWSæ§‹æˆã«é–¢å¿ƒãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"}
        ]
    
    if "cache_stats" not in st.session_state:
        st.session_state["cache_stats"] = {
            "total_requests": 0,
            "cache_hits": 0,
            "total_tokens_saved": 0
        }
    
    if "langchain_stats" not in st.session_state:
        st.session_state["langchain_stats"] = {
            "total_requests": 0,
            "successful_requests": 0
        }

def display_chat_history(messages=None):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º"""
    if messages is None:
        messages = st.session_state.messages
    for msg in messages:
        st.chat_message(msg["role"]).write(msg["content"])

def add_message_to_history(role: str, content: str):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ """
    st.session_state.messages.append({"role": role, "content": content})

def display_performance_stats():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’è¡¨ç¤º"""
    st.header("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
    stats = st.session_state["cache_stats"]
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°", stats["total_requests"])
        st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°", stats["cache_hits"])
    
    with col2:
        cache_hit_rate = (stats["cache_hits"] / max(stats["total_requests"], 1)) * 100
        st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡", f"{cache_hit_rate:.1f}%")
        st.metric("ç¯€ç´„ãƒˆãƒ¼ã‚¯ãƒ³æ•°(æ¨å®š)", stats["total_tokens_saved"])

def display_langchain_stats():
    """LangChainçµ±è¨ˆã‚’è¡¨ç¤º"""
    if "langchain_stats" in st.session_state:
        st.header("ğŸ¦œ LangChainçµ±è¨ˆ")
        lc_stats = st.session_state["langchain_stats"]
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("LangChainç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ", lc_stats["total_requests"])
        with col2:
            success_rate = (lc_stats["successful_requests"] / max(lc_stats["total_requests"], 1)) * 100
            st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")

def display_memory_stats(memory_manager):
    """ãƒ¡ãƒ¢ãƒªçµ±è¨ˆã‚’è¡¨ç¤º"""
    if memory_manager and memory_manager.is_available():
        try:
            from langchain_integration.memory_manager import ConversationAnalyzer
            
            st.subheader("ğŸ’­ ä¼šè©±ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ")
            conversation_analysis = ConversationAnalyzer.analyze_conversation(
                memory_manager.get_chat_history()
            )
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°", conversation_analysis.get("total_messages", 0))
                st.metric("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", conversation_analysis.get("user_message_count", 0))
            with col2:
                st.metric("AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", conversation_analysis.get("ai_message_count", 0))
                if conversation_analysis.get("topics"):
                    st.write("**æ¤œå‡ºãƒˆãƒ”ãƒƒã‚¯:**", ", ".join(conversation_analysis["topics"][:3]))
            
            # ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒœã‚¿ãƒ³
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                    memory_manager.clear_history()
                    st.session_state.messages = [
                        {"role": "assistant", "content": "ã©ã®ã‚ˆã†ãªAWSæ§‹æˆã«é–¢å¿ƒãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ"}
                    ]
                    st.rerun()
            with col2:
                if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                    history = memory_manager.export_history()
                    st.download_button(
                        "å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=json.dumps(history, ensure_ascii=False, indent=2),
                        file_name="chat_history.json",
                        mime="application/json"
                    )
        except ImportError:
            st.info("ä¼šè©±åˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

def display_settings_tab(bedrock_service):
    """è¨­å®šã‚¿ãƒ–ã‚’è¡¨ç¤º"""
    st.header("âš™ï¸ è¨­å®š")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
    enable_cache = st.checkbox(
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
        value=st.session_state.get("enable_cache", True)
    )
    st.session_state["enable_cache"] = enable_cache
    
    # LangChainè¨­å®š
    if bedrock_service.is_langchain_available():
        use_langchain = st.checkbox(
            "LangChainã‚’ä½¿ç”¨ã™ã‚‹",
            value=st.session_state.get("use_langchain", True)
        )
        st.session_state["use_langchain"] = use_langchain
        
        with st.expander("LangChainè©³ç´°è¨­å®š"):
            st.write("**åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:**")
            st.write("âœ… AWS Bedrockçµ±åˆ")
            st.write("âœ… ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç†")
            st.write("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
            
            try:
                from langchain_integration.mcp_tools import is_langchain_mcp_available
                if is_langchain_mcp_available():
                    st.write("âœ… MCP Toolsçµ±åˆ")
                else:
                    st.write("âŒ MCP Toolsçµ±åˆï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
            except ImportError:
                st.write("âŒ MCP Toolsçµ±åˆï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
    else:
        st.session_state["use_langchain"] = False
        st.info("ğŸ’¡ LangChainçµ±åˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    
    # çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
    if st.button("çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state["cache_stats"] = {
            "total_requests": 0,
            "cache_hits": 0,
            "total_tokens_saved": 0
        }
        st.session_state["langchain_stats"] = {
            "total_requests": 0,
            "successful_requests": 0
        }
        st.rerun()

def handle_chat_input(bedrock_service, memory_manager=None):
    """ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’å‡¦ç†"""
    if prompt := st.chat_input():
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        add_message_to_history("user", prompt)
        
        # ãƒ¡ãƒ¢ãƒªç®¡ç†ã«ã‚‚è¿½åŠ 
        if memory_manager and memory_manager.is_available():
            memory_manager.add_user_message(prompt)
        
        st.chat_message("user").write(prompt)
        
        # AIå¿œç­”ã‚’å–å¾—
        with st.chat_message("assistant"):
            with st.spinner("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
                full_response = ""
                message_placeholder = st.empty()
                
                # è¨­å®šå€¤ã‚’å–å¾—
                enable_cache = st.session_state.get("enable_cache", True)
                use_langchain = st.session_state.get("use_langchain", True)
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å‡¦ç†
                for chunk in bedrock_service.invoke_streaming(prompt, enable_cache, use_langchain):
                    full_response += chunk
                    message_placeholder.write(full_response + "â–Œ")
                
                message_placeholder.write(full_response)
        
        # AIå¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
        add_message_to_history("assistant", full_response)
        
        # ãƒ¡ãƒ¢ãƒªç®¡ç†ã«ã‚‚è¿½åŠ 
        if memory_manager and memory_manager.is_available():
            memory_manager.add_ai_message(full_response)

def display_cost_analysis_button():
    """ã‚³ã‚¹ãƒˆåˆ†æãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º"""
    # æœ€æ–°ã®AIå¿œç­”ã«AWSã‚µãƒ¼ãƒ“ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    auto_suggest = False
    if st.session_state.messages:
        latest_response = ""
        for message in reversed(st.session_state.messages):
            if message["role"] == "assistant":
                latest_response = message["content"].lower()
                break
        
        # AWSã‚µãƒ¼ãƒ“ã‚¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        aws_keywords = ["ec2", "s3", "rds", "lambda", "cloudfront", "dynamodb", 
                       "vpc", "ecs", "eks", "load balancer", "elasticache"]
        auto_suggest = any(keyword in latest_response for keyword in aws_keywords)
    
    # ãƒœã‚¿ãƒ³ã®è¡¨ç¤º
    button_type = "primary" if auto_suggest else "secondary"
    button_text = "ğŸ’° ã“ã®æ§‹æˆã®ã‚³ã‚¹ãƒˆæ¦‚ç®—ã‚’ç¢ºèª" + (" (æ¨å¥¨)" if auto_suggest else "")
    
    if auto_suggest:
        st.info("ğŸ’¡ AWSæ§‹æˆãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    
    if st.button(button_text, type=button_type, use_container_width=True):
        st.session_state.show_cost_analysis = True
        st.rerun()

def display_cost_analysis_ui(mcp_client):
    """ã‚³ã‚¹ãƒˆåˆ†æUIã‚’è¡¨ç¤º"""
    if not st.session_state.get("show_cost_analysis", False):
        return
    
    st.subheader("ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æ")
    
    # æœ€æ–°ã®AIå¿œç­”ã‹ã‚‰AWSã‚µãƒ¼ãƒ“ã‚¹ã‚’æŠ½å‡º
    latest_response = ""
    for message in reversed(st.session_state.messages):
        if message["role"] == "assistant":
            latest_response = message["content"]
            break
    
    if not latest_response:
        st.warning("ã‚³ã‚¹ãƒˆåˆ†æå¯¾è±¡ã®æ§‹æˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # AWSã‚µãƒ¼ãƒ“ã‚¹å€™è£œã‚’è¡¨ç¤º
    aws_services = [
        "Amazon EC2", "Amazon S3", "Amazon RDS", "Amazon CloudFront",
        "AWS Lambda", "Amazon DynamoDB", "Amazon VPC", "Amazon ECS",
        "Amazon EKS", "Application Load Balancer", "Network Load Balancer",
        "Amazon ElastiCache", "Amazon SQS", "Amazon SNS", "Amazon CloudWatch"
    ]
    
    st.write("**åˆ†æå¯¾è±¡ã®AWSã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š**")
    selected_services = st.multiselect(
        "ã‚µãƒ¼ãƒ“ã‚¹é¸æŠ",
        aws_services,
        default=[],
        help="ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œã—ãŸã„AWSã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    if selected_services:
        st.write("**åˆ©ç”¨è¦æ¨¡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š**")
        
        usage_params = {}
        for service in selected_services:
            with st.expander(f"ğŸ“Š {service} ã®åˆ©ç”¨è¦æ¨¡"):
                if "EC2" in service:
                    usage_params[service] = {
                        "instance_type": st.selectbox(f"{service} ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—", ["t3.micro", "t3.small", "t3.medium", "t3.large", "m5.large", "m5.xlarge"], key=f"{service}_type"),
                        "instance_count": st.number_input(f"{service} ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°", min_value=1, max_value=100, value=1, key=f"{service}_count"),
                        "hours_per_month": st.number_input(f"{service} æœˆé–“ç¨¼åƒæ™‚é–“", min_value=1, max_value=744, value=744, key=f"{service}_hours")
                    }
                elif "S3" in service:
                    usage_params[service] = {
                        "storage_gb": st.number_input(f"{service} ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ (GB)", min_value=1, max_value=10000, value=100, key=f"{service}_storage"),
                        "requests_per_month": st.number_input(f"{service} æœˆé–“ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°", min_value=1000, max_value=10000000, value=100000, key=f"{service}_requests")
                    }
                elif "RDS" in service:
                    usage_params[service] = {
                        "instance_type": st.selectbox(f"{service} ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—", ["db.t3.micro", "db.t3.small", "db.t3.medium", "db.m5.large"], key=f"{service}_db_type"),
                        "storage_gb": st.number_input(f"{service} ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ (GB)", min_value=20, max_value=1000, value=100, key=f"{service}_db_storage"),
                        "multi_az": st.checkbox(f"{service} ãƒãƒ«ãƒAZæ§‹æˆ", key=f"{service}_multi_az")
                    }
                elif "Lambda" in service:
                    usage_params[service] = {
                        "executions_per_month": st.number_input(f"{service} æœˆé–“å®Ÿè¡Œå›æ•°", min_value=1000, max_value=100000000, value=1000000, key=f"{service}_executions"),
                        "memory_mb": st.selectbox(f"{service} ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ (MB)", [128, 256, 512, 1024, 2048, 3008], key=f"{service}_memory"),
                        "duration_ms": st.number_input(f"{service} å¹³å‡å®Ÿè¡Œæ™‚é–“ (ms)", min_value=100, max_value=15000, value=1000, key=f"{service}_duration")
                    }
                else:
                    # ãã®ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ç”¨ã®æ±ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    usage_params[service] = {
                        "usage_scale": st.selectbox(f"{service} åˆ©ç”¨è¦æ¨¡", ["å°è¦æ¨¡", "ä¸­è¦æ¨¡", "å¤§è¦æ¨¡"], key=f"{service}_scale")
                    }
        
        # ã‚³ã‚¹ãƒˆè¨ˆç®—å®Ÿè¡Œãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ’¸ ã‚³ã‚¹ãƒˆè¨ˆç®—ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
                return perform_cost_analysis(selected_services, usage_params, latest_response, mcp_client)
    
    # é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³
    if st.button("âŒ ã‚³ã‚¹ãƒˆåˆ†æã‚’é–‰ã˜ã‚‹"):
        st.session_state.show_cost_analysis = False
        st.rerun()
    
    return None

def perform_cost_analysis(selected_services, usage_params, architecture_context, mcp_client):
    """ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œ"""
    st.info("ğŸ”„ ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œä¸­...")
    
    # BedrockServiceã®å–å¾—
    if "bedrock_service" not in st.session_state:
        st.error("BedrockServiceãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None
    
    bedrock_service = st.session_state.bedrock_service
    
    # ã‚³ã‚¹ãƒˆè¨ˆç®—ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿
    try:
        import os
        current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        prompt_path = os.path.join(current_dir, "prompts", "cost_calculation_prompt.txt")
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            cost_calculation_prompt = f.read()
    except Exception as e:
        st.error(f"ã‚³ã‚¹ãƒˆè¨ˆç®—ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None
    
    # æ–™é‡‘æƒ…å ±ã®åé›†
    pricing_data = {}
    with st.spinner("AWSæ–™é‡‘æƒ…å ±ã‚’åé›†ä¸­..."):
        for service in selected_services:
            try:
                # MCPçµŒç”±ã§AWSæ–™é‡‘æƒ…å ±ã‚’å–å¾—
                pricing_info = mcp_client.get_aws_documentation(f"{service} pricing ap-northeast-1 tokyo region cost calculator")
                pricing_data[service] = pricing_info
            except Exception as e:
                st.warning(f"{service}ã®æ–™é‡‘æƒ…å ±å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                pricing_data[service] = {"error": str(e)}
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    services_info = []
    for service in selected_services:
        params = usage_params.get(service, {})
        service_info = f"- **{service}**: {params}"
        if service in pricing_data:
            service_info += f"\n  æ–™é‡‘æƒ…å ±: {pricing_data[service]}"
        services_info.append(service_info)
    
    full_prompt = f"""
{cost_calculation_prompt}

## åˆ†æå¯¾è±¡

### AWSã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
{architecture_context}

### é¸æŠã•ã‚ŒãŸã‚µãƒ¼ãƒ“ã‚¹ã¨åˆ©ç”¨è¦æ¨¡
{chr(10).join(services_info)}

### è¦æ±‚äº‹é …
ä¸Šè¨˜ã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€è©³ç´°ãªã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œã—ã€æŒ‡å®šã•ã‚ŒãŸå‡ºåŠ›å½¢å¼ã§çµæœã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
1. æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆap-northeast-1ï¼‰ã®æ–™é‡‘ã‚’åŸºæº–ã¨ã™ã‚‹
2. å®Ÿéš›ã®åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªè¦‹ç©ã‚‚ã‚Š
3. ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®å…·ä½“çš„ãªææ¡ˆ
4. è¨ˆç®—æ ¹æ‹ ã®æ˜ç¢ºãªèª¬æ˜
"""

    # Bedrockã§ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œ
    with st.spinner("AI ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œä¸­..."):
        try:
            full_response = ""
            response_placeholder = st.empty()
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã‚³ã‚¹ãƒˆåˆ†æçµæœã‚’å–å¾—
            for chunk in bedrock_service.invoke_streaming(
                full_prompt,
                enable_cache=st.session_state.get("enable_cache", True),
                use_langchain=st.session_state.get("use_langchain", True)
            ):
                full_response += chunk
                response_placeholder.markdown(full_response + "â–Œ")
            
            response_placeholder.markdown(full_response)
            
            # åˆ†æçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state.latest_cost_analysis = {
                "services": selected_services,
                "params": usage_params,
                "result": full_response,
                "timestamp": st.session_state.get("timestamp", "ä¸æ˜")
            }
            
            return {"analysis": full_response, "services": selected_services}
            
        except Exception as e:
            st.error(f"ã‚³ã‚¹ãƒˆåˆ†æã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None

def calculate_service_cost(service_name, usage_params, pricing_info):
    """ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # å®Ÿéš›ã®MCPçµ±åˆæ™‚ã¯ã‚ˆã‚Šè©³ç´°ãªè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
    base_costs = {
        "Amazon EC2": {"t3.micro": 0.0104, "t3.small": 0.0208, "t3.medium": 0.0416, "t3.large": 0.0832, "m5.large": 0.096, "m5.xlarge": 0.192},
        "Amazon S3": {"storage": 0.023, "requests": 0.0004},
        "Amazon RDS": {"db.t3.micro": 0.017, "db.t3.small": 0.034, "db.t3.medium": 0.068, "db.m5.large": 0.192},
        "AWS Lambda": {"execution": 0.0000002, "memory": 0.0000166667}
    }
    
    try:
        if "EC2" in service_name:
            instance_type = usage_params.get("instance_type", "t3.micro")
            instance_count = usage_params.get("instance_count", 1)
            hours = usage_params.get("hours_per_month", 744)
            hourly_rate = base_costs["Amazon EC2"].get(instance_type, 0.0104)
            return hourly_rate * instance_count * hours
            
        elif "S3" in service_name:
            storage_gb = usage_params.get("storage_gb", 100)
            requests = usage_params.get("requests_per_month", 100000)
            storage_cost = storage_gb * base_costs["Amazon S3"]["storage"]
            request_cost = requests * base_costs["Amazon S3"]["requests"] / 1000
            return storage_cost + request_cost
            
        elif "RDS" in service_name:
            instance_type = usage_params.get("instance_type", "db.t3.micro")
            storage_gb = usage_params.get("storage_gb", 100)
            multi_az = usage_params.get("multi_az", False)
            hourly_rate = base_costs["Amazon RDS"].get(instance_type, 0.017)
            instance_cost = hourly_rate * 744 * (2 if multi_az else 1)
            storage_cost = storage_gb * 0.115  # GP2 storage cost
            return instance_cost + storage_cost
            
        elif "Lambda" in service_name:
            executions = usage_params.get("executions_per_month", 1000000)
            memory_mb = usage_params.get("memory_mb", 128)
            duration_ms = usage_params.get("duration_ms", 1000)
            
            execution_cost = executions * base_costs["AWS Lambda"]["execution"]
            compute_cost = executions * (memory_mb / 1024) * (duration_ms / 1000) * base_costs["AWS Lambda"]["memory"]
            return execution_cost + compute_cost
            
        else:
            # ãã®ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã®ç°¡æ˜“è¨ˆç®—
            scale = usage_params.get("usage_scale", "å°è¦æ¨¡")
            scale_multiplier = {"å°è¦æ¨¡": 10, "ä¸­è¦æ¨¡": 50, "å¤§è¦æ¨¡": 200}
            return scale_multiplier.get(scale, 10)
            
    except Exception:
        return 10.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
