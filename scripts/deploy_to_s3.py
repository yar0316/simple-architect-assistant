#!/usr/bin/env python3
"""
S3ç½²åä»˜ãURLé…å¸ƒã®è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Simple Architect Assistant ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ç½²åä»˜ãURLã‚’ç”Ÿæˆ
"""

import os
import sys
import json
import argparse
import subprocess
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any
import logging

try:
    import boto3
    from botocore.exceptions import ClientError, NoCredentialsError
    BOTO3_AVAILABLE = True
except ImportError:
    BOTO3_AVAILABLE = False


class S3Deployer:
    """S3é…å¸ƒç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_file: Optional[str] = None):
        """
        S3é…å¸ƒç®¡ç†ã‚’åˆæœŸåŒ–
        
        Args:
            config_file: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.logger = self._setup_logging()
        self.config = self._load_config(config_file)
        self.project_root = Path(__file__).parent.parent
        
        if not BOTO3_AVAILABLE:
            self.logger.error("boto3ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: pip install boto3")
            sys.exit(1)
        
        self.s3_client = None
        self._init_aws_client()
    
    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    def _load_config(self, config_file: Optional[str]) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if config_file:
            config_path = Path(config_file)
        else:
            config_path = self.project_root / "config" / "distribution.json"
        
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            "s3": {
                "bucket_name": os.getenv("S3_BUCKET_NAME", ""),
                "region": os.getenv("AWS_REGION", "us-east-1"),
                "profile": os.getenv("AWS_PROFILE", "default"),
                "prefix": "releases/simple-architect-assistant/",
                "presign_expiry_days": 7
            }
        }
    
    def _init_aws_client(self):
        """AWS S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            session = boto3.Session(
                profile_name=self.config["s3"]["profile"],
                region_name=self.config["s3"]["region"]
            )
            self.s3_client = session.client('s3')
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            self.s3_client.list_buckets()
            self.logger.info(f"AWS S3æ¥ç¶šæˆåŠŸ: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«={self.config['s3']['profile']}")
            
        except NoCredentialsError:
            self.logger.error("AWSèªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚AWS CLIã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)
        except ClientError as e:
            self.logger.error(f"AWS S3æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def build_app(self, version: str, clean: bool = True) -> Path:
        """ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚’ãƒ“ãƒ«ãƒ‰"""
        self.logger.info(f"ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªãƒ“ãƒ«ãƒ‰é–‹å§‹: ãƒãƒ¼ã‚¸ãƒ§ãƒ³={version}")
        
        # ãƒ“ãƒ«ãƒ‰ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
        build_cmd = ["python", "build_desktop_app.py", "--version", version]
        if clean:
            build_cmd.append("--clean")
        
        try:
            # ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ
            result = subprocess.run(
                build_cmd,
                cwd=self.project_root,
                check=True,
                capture_output=True,
                text=True
            )
            
            self.logger.info("ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªãƒ“ãƒ«ãƒ‰å®Œäº†")
            self.logger.debug(f"ãƒ“ãƒ«ãƒ‰å‡ºåŠ›: {result.stdout}")
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ‡ã‚£ã‚¹ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹ã‚’è¿”ã™
            dist_dir = self.project_root / "dist" / "simple-architect-assistant"
            if not dist_dir.exists():
                raise FileNotFoundError(f"ãƒ“ãƒ«ãƒ‰çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dist_dir}")
            
            return dist_dir
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼: {e.stderr}")
            sys.exit(1)
    
    def create_distribution_archive(self, dist_dir: Path, version: str) -> Path:
        """é…å¸ƒç”¨ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ä½œæˆ"""
        self.logger.info("é…å¸ƒç”¨ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆä¸­...")
        
        archive_name = f"simple-architect-assistant-{version}.zip"
        archive_path = self.project_root / "dist" / archive_name
        
        # æ—¢å­˜ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å‰Šé™¤
        if archive_path.exists():
            archive_path.unlink()
        
        try:
            # ZIPåœ§ç¸®
            subprocess.run([
                "zip", "-r", archive_name, "simple-architect-assistant"
            ], cwd=self.project_root / "dist", check=True)
            
            self.logger.info(f"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆå®Œäº†: {archive_path}")
            return archive_path
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®SHA256ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    
    def upload_to_s3(self, file_path: Path, version: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        bucket_name = self.config["s3"]["bucket_name"]
        if not bucket_name:
            self.logger.error("S3ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            sys.exit(1)
        
        # S3ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        prefix = self.config["s3"]["prefix"]
        s3_key = f"{prefix}{file_path.name}"
        
        self.logger.info(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {file_path.name} -> s3://{bucket_name}/{s3_key}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
            file_hash = self.calculate_file_hash(file_path)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            metadata = {
                'version': version,
                'upload_date': datetime.utcnow().isoformat(),
                'sha256': file_hash,
                'source': 'simple-architect-assistant-build-script'
            }
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            self.s3_client.upload_file(
                str(file_path),
                bucket_name,
                s3_key,
                ExtraArgs={
                    'Metadata': metadata,
                    'ServerSideEncryption': 'AES256'
                }
            )
            
            self.logger.info(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: s3://{bucket_name}/{s3_key}")
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ (SHA256): {file_hash}")
            
            return s3_key
            
        except ClientError as e:
            self.logger.error(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def generate_presigned_url(self, s3_key: str, expiry_days: Optional[int] = None) -> str:
        """ç½²åä»˜ãURLã‚’ç”Ÿæˆ"""
        bucket_name = self.config["s3"]["bucket_name"]
        if expiry_days is None:
            expiry_days = self.config["s3"]["presign_expiry_days"]
        
        expiry_seconds = expiry_days * 24 * 60 * 60
        
        try:
            presigned_url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={'Bucket': bucket_name, 'Key': s3_key},
                ExpiresIn=expiry_seconds
            )
            
            expiry_date = datetime.utcnow() + timedelta(days=expiry_days)
            self.logger.info(f"ç½²åä»˜ãURLç”Ÿæˆå®Œäº†")
            self.logger.info(f"æœ‰åŠ¹æœŸé™: {expiry_date.strftime('%Y-%m-%d %H:%M:%S')} UTC ({expiry_days}æ—¥é–“)")
            
            return presigned_url
            
        except ClientError as e:
            self.logger.error(f"ç½²åä»˜ãURLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def create_deployment_info(self, s3_key: str, presigned_url: str, version: str, file_path: Path) -> Dict[str, Any]:
        """é…å¸ƒæƒ…å ±ã‚’ä½œæˆ"""
        file_hash = self.calculate_file_hash(file_path)
        expiry_date = datetime.utcnow() + timedelta(days=self.config["s3"]["presign_expiry_days"])
        
        return {
            "deployment_info": {
                "version": version,
                "timestamp": datetime.utcnow().isoformat(),
                "file_name": file_path.name,
                "file_size": file_path.stat().st_size,
                "sha256": file_hash,
                "s3_location": {
                    "bucket": self.config["s3"]["bucket_name"],
                    "key": s3_key,
                    "region": self.config["s3"]["region"]
                },
                "download": {
                    "presigned_url": presigned_url,
                    "expires_at": expiry_date.isoformat(),
                    "expiry_days": self.config["s3"]["presign_expiry_days"]
                }
            }
        }
    
    def save_deployment_info(self, deployment_info: Dict[str, Any], output_file: Optional[str] = None):
        """é…å¸ƒæƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if output_file:
            output_path = Path(output_file)
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.project_root / f"deployment_info_{timestamp}.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(deployment_info, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"é…å¸ƒæƒ…å ±ã‚’ä¿å­˜: {output_path}")
    
    def deploy(self, version: str, clean: bool = True, save_info: bool = True) -> Dict[str, Any]:
        """å®Œå…¨ãªé…å¸ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        self.logger.info("=== S3é…å¸ƒãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ ===")
        
        # 1. ã‚¢ãƒ—ãƒªãƒ“ãƒ«ãƒ‰
        dist_dir = self.build_app(version, clean)
        
        # 2. ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ
        archive_path = self.create_distribution_archive(dist_dir, version)
        
        # 3. S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        s3_key = self.upload_to_s3(archive_path, version)
        
        # 4. ç½²åä»˜ãURLç”Ÿæˆ
        presigned_url = self.generate_presigned_url(s3_key)
        
        # 5. é…å¸ƒæƒ…å ±ä½œæˆ
        deployment_info = self.create_deployment_info(s3_key, presigned_url, version, archive_path)
        
        if save_info:
            self.save_deployment_info(deployment_info)
        
        self.logger.info("=== S3é…å¸ƒãƒ—ãƒ­ã‚»ã‚¹å®Œäº† ===")
        
        # çµæœè¡¨ç¤º
        print("\n" + "="*60)
        print("ğŸ‰ S3é…å¸ƒå®Œäº†")
        print("="*60)
        print(f"ğŸ“¦ ãƒ•ã‚¡ã‚¤ãƒ«å: {archive_path.name}")
        print(f"ğŸ·ï¸  ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {version}")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {archive_path.stat().st_size / (1024*1024):.1f} MB")
        print(f"ğŸ”’ SHA256: {deployment_info['deployment_info']['sha256']}")
        print(f"â˜ï¸  S3ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: s3://{self.config['s3']['bucket_name']}/{s3_key}")
        print(f"â° æœ‰åŠ¹æœŸé™: {self.config['s3']['presign_expiry_days']}æ—¥é–“")
        print(f"\nğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL:")
        print(f"{presigned_url}")
        print("\n" + "="*60)
        
        return deployment_info


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='Simple Architect Assistant S3é…å¸ƒãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--version', '-v', required=True, help='ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå· (ä¾‹: 1.0.0)')
    parser.add_argument('--config', '-c', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--no-clean', action='store_true', help='ãƒ“ãƒ«ãƒ‰å‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--no-save', action='store_true', help='é…å¸ƒæƒ…å ±ã®ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--output', '-o', help='é…å¸ƒæƒ…å ±ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    try:
        deployer = S3Deployer(args.config)
        deployment_info = deployer.deploy(
            version=args.version,
            clean=not args.no_clean,
            save_info=not args.no_save
        )
        
        if args.output:
            deployer.save_deployment_info(deployment_info, args.output)
            
    except KeyboardInterrupt:
        print("\né…å¸ƒãƒ—ãƒ­ã‚»ã‚¹ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        logging.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()